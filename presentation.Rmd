---
title: "Models for Non-Monotone Missing at Random Data"
author: "David Luke Thiessen"
date: "October 15, 2018"
output: 
  beamer_presentation:
    slide_level: 2
    includes:
      in_header: headerpagenumbers.tex

bibliography: bibliography.bibtex
nocite: | 
  @LittleRoderickJ.A.2002SAwM
  @RubinDonaldB.1976IaMD
  @HorvitzD.G.1952AGoS
  @SunBaoluo2017OIPW
  @SchaferJosephL.2002MDOV
  @SeamanShaunR2013Roip
  @ZhangDao-Qiang2003CIDU
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Outline
- Introduction 
- Background on Missing Data Theory
- Approaches for Analyzing Missing Data
- Simulation Example
- Inverse Probability Weighting
- Methods for Modelling Missing Data Probabilities


## Introduction
In the basic statistical structure, there is a "population" consisting of a collection of individuals. We are interested in studying some aspect of the population (commonly a single characteristic or a relation between several characteristics), but for reasons of cost/time/convenience, are unable to take an observation from every individual.

Our approach is to randomly select a portion of the population, record observations from these individuals, then make generalizations to the rest of the population.


## Introduction: Example
A retirement home has 100 residents and we want to know if the residents have high blood pressure. We randomly selects 30 residents to record their blood pressure.

The estimate of average blood pressure is:

\begin{equation}
\bar{x} = \frac{1}{30}\sum_{i=1}^{30} x_i
\end{equation}

and (under typical assumptions) the confidence interval would be:

\begin{equation}
(\bar{x} - z_{\alpha/2}\frac{s}{\sqrt{30}}, \, \bar{x} + z_{\alpha/2}\frac{s}{\sqrt{30}})
\end{equation}


## Introduction: The Problem
Some of the retirees refuse, and won't let us measure their blood pressure.

How should we calculate the estimate and confidence interval?

Remark: Missingness is a nuisance, not the objective of scientific study.

Question: Can auxiliary information (like the age of the residents) be used to recover (or estimate) the missing information?


## Introduction: A Naive Approach
We could decide to ignore the residents who refuse and estimates the average as:

\begin{equation}
\bar{x} = \frac{1}{|J|}\sum_{i \in J} x_i
\end{equation}

Where J is the set of residents in the sample who let their blood pressure be recorded.

Will this approach give an accurate estimate?

Answer: It depends, but in general this estimate is biased.


## Background: Notation
As in @SunBaoluo2017OIPW, we let $X = (X_1, X_2, ..., X_K)$ be a random vector representing the complete (fully observed) data.

Let $R$ be an integer variable denoting which of the $X_i$ variables have been observed, with $1 \leq R \leq 2^K$. Let $R = 1$ indicate that all variables observed and $R = r > 1$ denote that only the variables $X_{(r)} \subset X$ are observed (which could be the empty set).

Each individual is an independent and identically distributed observation from the random variable $(R_i, X_{(R)i})$. 


## Background: Missing Data Patterns
If the variables $X_i$ can be arranged such that $X_{(r+1)} \subset X_{(r)}$, then the data are said to have a monotone missing pattern.

```{r}
X = c(6,4,4,3,2)
barplot(X,axes=FALSE,main="Monotone Missing",names.arg=c("X1","X2","X3","X4","X5"),density=c(rep(20,5)))
```


## Background: Missing Data Patterns
If the variables are not monotone missing, then they are non-monotone missing.

```{r}
X = c(6,4,4,3,2)
barplot(X,axes=FALSE,main="Non-monotone Missing",names.arg=c("X1","X2","X3","X4","X5"),density=c(rep(20,5)))
rect(xleft = 2.6, ybottom = 5, xright = 3.6, ytop = 6, density = 20,lwd=0.6)
rect(xleft = 5, ybottom = 3, xright = 6, ytop = 5, density = 20,lwd=0.6)
```


## Background: Missing Data Mechanisms
Missing Completely at Random (MCAR)

- Missingness is independent of the data.
- Example: The device we are using to record blood pressure is faulty, and the device randomly fails when trying to use it on some residents.

\begin{equation}
\pi_r(x) = P(R = r|x,\gamma) = P(R=r|\gamma)
\end{equation}


## Background: Missing Data Mechanisms
Missing at Random (MAR)

- Missingness can depend on data values that are observed, but not those that are unobserved.
- Example: The residents are more likely to refuse the older they are (and the worker has a list of the ages of residents).

\begin{equation}
\pi_r(x) = P(R=r|x,\gamma) = P(R=r|x^{\text{obs}},\gamma)
\end{equation}


## Background: Missing Data Mechanisms
Missing Not at Random (MNAR)

- Neither of the two above conditions hold.
- Example: Residents with high blood pressure are more likely to refuse to have their blood pressure recorded.


## Background: Examples of Missing Data Mechanisms
Suppose that the data in question is $(X_1,X_2) \sim \text{N}(\mu,\Sigma)$, where $\mu = (1,1)$, $\Sigma = \bigl( \begin{smallmatrix} 1 & 0.5 \\ 0.5 & 1\end{smallmatrix}\bigr)$ and the research objective is to study the variable $X_2$.

Let $X_1$ be always observed, and $X_2$ partially missing with the mechanism given by:

- MCAR: $P(R=2|x,\gamma) = P(R=2) = 0.3$

- MAR: $P(R=2|x,\gamma) = P(R=2|x_1) = 1/(1+e^{x_1})$

- MNAR: $P(R=2|x,\gamma) = P(R=2|x_2) = 1/(1+e^{x_2})$


## Background: Missing Data Mechanisms
Remark: For technical reasons, we also need to make the assumption that:

\begin{equation}
\pi_1(x) = P(R = 1|x,\gamma) > \sigma > 0
\end{equation}

for some constant $\sigma$ and all possible $x$.


## Approaches for Analyzing with Missing Data
- Complete Case Analysis (CC)
    - Throw out the individuals with missing data, and do an analysis as if you had only measured "r" individuals instead of the originally planned "n".
    
- Inverse Probability Weighting (IPW)
    - Weight the different individuals differently in the analysis, making ones with rare observations carry more weight.
    
- Single Imputation (SI)
    - Replace the missing values with new appropriately selected values.
    
- Multiple Imputation (MI)
    - Replace missing values with appropriately selected values, but repeat this many (typically 5 - 20 times) and then combine the conclusions together.
    
- Other Approaches: Maximum Likelihood, Matching


## Simulation: Setting
$(X_1,X_2) \sim \text{N}(\mu,\Sigma)$, $\mu = (1,1)$, $\Sigma = \bigl( \begin{smallmatrix} 1 & 0.5 \\ 0.5 & 1\end{smallmatrix}\bigr)$ 

Let $X_1$ be always observed, and $X_2$ partially missing with the mechanism given by:

- MCAR: $P(R=2|x,\gamma) = P(R=2) = 0.3$

- MAR: $P(R=2|x,\gamma) = P(R=2|x_1) = 1/(1+e^{x_1})$

- MNAR: $P(R=2|x,\gamma) = P(R=2|x_2) = 1/(1+e^{x_2})$

$n = 30$, number of simulations $= 1000$


## Simulation: Results
```{r, include=TRUE,echo=TRUE}
load(".Rdata")
colMeans(SimResults[,c(1,2,3)])
colMeans(SimResults[,c(4,5,6)])
```


## Simulation: Results
```{r, include=TRUE,echo=TRUE}
load(".Rdata")
colMeans(SimResults[,c(7,8,9)])
colMeans(SimResults[,c(10,11,12)])

```


## Simulation: Single Imputation Comparison
```{r}
load(".Rdata")
plot(1, type="n", xlab="X1", ylab="X2", xlim=c(-2, 4), ylim=c(-2, 4),
     main="Single Imputation - MAR")
points(x=mydata[which(mydata$X4==1),]$X1,y=mydata[which(mydata$X4==1),]$X2,pch=19)

abline(h=mean(mydata[which(mydata$X4==1),]$X2),col="Blue")
points(x=mydata[which(mydata$X4==0),]$X1,
       y=rep(mean(mydata[which(mydata$X4==1),]$X2),n-sum(mydata$X4)),
       col="Blue",pch=19)

abline(model5,col="red")
points(x=mydata[which(mydata$X4==0),]$X1,
       y=predict(model5,newdata=data.frame("X1"=mydata[which(mydata$X4==0),1])),
       col="red",pch=19)

abline(h=mean(completed5),col="Orange")

```


## Simulation: Inverse Probability Weighting

\begin{equation}
\bar{x_{2}} = \frac{1}{r}\sum_{i = 1}^{r} w_{i}x_{i2}
\end{equation}

\begin{equation}
w_{i} = \frac{r\pi_{i}^{-1}}{\sum_{j = 1}^{r}\pi_{j}^{-1}}
\end{equation}

where $\pi_{i} = \pi_{1}(x_{i})$ is obtained by regressing the indicator for missingness on $X_1$ using logistic regression.


## Inverse Probability Weighting
### Advantages
- Easier to use than Likelihood approaches
- Don't need to specify a complicated imputation model if there is structure to the data
- Augmented techniques are consistent if at least one of the missing model or the regression model is correctly specified

### Disadvantages
- Difficult to specify a missingness model if the data are non-monotone
- Less efficient than Multiple Imputation


## Modelling Missing Data Probability
- Logistic
- Clustering and Empirical Likelihood
- Multinomial with only a few missing patterns and lots of data
- Unconstrained Maximum Likelihood and Constrained Bayesian Estimation from @SunBaoluo2017OIPW


## Logistic
```{r,include=TRUE}
load(".Rdata")
model1 = glm(X4~X1,data=data.frame(mydata),family=binomial(link="logit"))
plot(mydata[,1],mydata[,4],xlab="X1",ylab="Missing Indicator",pch=19)
curve(predict(model1,data.frame(X1=x),type="resp"),add=TRUE,col="red")

```

## Clusters
```{r,include=TRUE}
load(".Rdata")
model1 = glm(X4~X1,data=data.frame(mydata),family=binomial(link="logit"))
plot(mydata[,1],mydata[,4],xlab="X1",ylab="Missing Indicator",pch=19)
abline(v=0.4)
abline(v=1.6)
segments(x0=-1.5,y0=(1/6),x1=0.4,col="red")
segments(x0=0.4,y0=(7/12),x1=1.6,col="red")
segments(x0=1.6,y0=1,x1=3.1,col="red")

```

## So what about Non-Monotone?


## Future Work


## References {.allowframebreaks}




